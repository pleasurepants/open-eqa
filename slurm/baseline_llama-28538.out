Mon Jan 20 05:22:30 PM CET 2025
worker-5
/home/wiss/zhang/anaconda3/envs/openeqa/bin/python
Running on MASTER_NODE=worker-5, MASTER_PORT=8214, RDZV_ID=25997
Monitoring CUDA and CPU usage...
index, name, utilization.gpu [%], utilization.memory [%], memory.total [MiB], memory.used [MiB], memory.free [MiB]
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.2 us,  0.9 sy,  0.1 ni, 98.5 id,  0.2 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 388894.0 free,   7594.2 used, 122695.7 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 508202.0 avail Mem 
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
found 1,636 questions
found 1,636 questions
found 1,636 questions
found 1,636 questions
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  3.2 sy,  0.0 ni, 96.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384159.4 free,  12082.2 used, 122941.8 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503714.0 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  3.6 sy,  0.1 ni, 96.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 385388.1 free,  10844.9 used, 122950.4 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 504951.3 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.2 us,  3.1 sy,  0.0 ni, 96.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 385307.6 free,  10925.4 used, 122950.4 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 504870.8 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.1 us,  3.3 sy,  0.0 ni, 96.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384445.8 free,  11785.1 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 504011.1 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  3.0 sy,  0.0 ni, 96.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 383571.9 free,  12661.0 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503135.2 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.2 us,  2.9 sy,  0.0 ni, 96.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384215.4 free,  12017.5 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503778.7 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  3.0 sy,  0.1 ni, 96.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384530.5 free,  11702.4 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 504093.8 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  3.0 sy,  0.0 ni, 96.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384786.2 free,  11446.6 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 504349.6 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  3.3 sy,  0.1 ni, 96.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384676.9 free,  11556.0 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 504240.2 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.1 us,  3.2 sy,  0.0 ni, 96.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 383908.6 free,  12323.3 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503472.9 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  3.2 sy,  0.0 ni, 96.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 383154.6 free,  13078.2 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 502718.0 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  2.9 sy,  0.0 ni, 96.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 383995.3 free,  12237.5 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503558.7 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  2.9 sy,  0.0 ni, 96.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384444.2 free,  11788.7 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 504007.5 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  2.9 sy,  0.1 ni, 96.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384222.0 free,  12010.8 used, 122950.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503785.4 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  2.9 sy,  0.0 ni, 96.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384268.5 free,  11964.3 used, 122950.6 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503831.8 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  3.3 sy,  0.1 ni, 96.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384011.0 free,  12221.7 used, 122950.8 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503574.6 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.2 us,  2.9 sy,  0.0 ni, 96.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 384139.1 free,  12093.5 used, 122950.8 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503702.7 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.2 us,  3.3 sy,  0.1 ni, 96.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 383821.8 free,  12410.8 used, 122950.8 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503385.4 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.1 us,  3.1 sy,  0.0 ni, 96.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 383791.8 free,  12440.7 used, 122950.8 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 503355.5 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.3 us,  2.9 sy,  0.0 ni, 96.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 382022.6 free,  14210.0 used, 122950.9 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 501586.2 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
%Cpu(s):  0.2 us,  2.9 sy,  0.1 ni, 96.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 382743.0 free,  13489.5 used, 122950.9 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 502306.7 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 0 MiB, 48676 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]%Cpu(s):  0.2 us,  3.2 sy,  0.0 ni, 96.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 382115.8 free,  14109.3 used, 123118.3 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 501686.9 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1238 MiB, 47437 MiB
%Cpu(s):  0.3 us,  3.3 sy,  0.2 ni, 96.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 380343.8 free,  14928.3 used, 124071.3 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 500867.9 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 8822 MiB, 39853 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 16118 MiB, 32557 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 21878 MiB, 26797 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
%Cpu(s):  0.3 us,  2.5 sy,  0.1 ni, 96.5 id,  0.5 wa,  0.0 hi,  0.1 si,  0.0 st 
MiB Mem : 515796.2 total, 377692.9 free,  15929.7 used, 125720.9 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 499866.5 avail Mem 
0, NVIDIA RTX A6000, 59 %, 3 %, 49140 MiB, 29046 MiB, 19629 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 34934 MiB, 13741 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
%Cpu(s):  0.3 us,  2.9 sy,  0.0 ni, 96.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 376043.4 free,  15946.5 used, 127353.5 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 499849.7 avail Mem 
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 38518 MiB, 10157 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 47990 MiB, 685 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
%Cpu(s):  0.3 us,  3.0 sy,  0.1 ni, 96.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 374924.0 free,  15443.1 used, 128976.4 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 500353.1 avail Mem 
Loading checkpoint shards:   0%|          | 0/15 [00:47<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:47<?, ?it/s]

Loading checkpoint shards:   0%|          | 0/15 [00:47<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:47<?, ?it/s]

Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/wiss/zhang/code/open-eqa/openeqa/baselines/llama.py", line 159, in <module>
  File "/home/wiss/zhang/code/open-eqa/openeqa/baselines/llama.py", line 159, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/wiss/zhang/code/open-eqa/openeqa/baselines/llama.py", line 159, in <module>
  File "/home/wiss/zhang/code/open-eqa/openeqa/baselines/llama.py", line 159, in <module>
            main(parse_args())main(parse_args())main(parse_args())


  File "/home/wiss/zhang/code/open-eqa/openeqa/baselines/llama.py", line 117, in main
  File "/home/wiss/zhang/code/open-eqa/openeqa/baselines/llama.py", line 117, in main
  File "/home/wiss/zhang/code/open-eqa/openeqa/baselines/llama.py", line 117, in main
    main(parse_args())
  File "/home/wiss/zhang/code/open-eqa/openeqa/baselines/llama.py", line 117, in main
                model = LLaMARunner(model = LLaMARunner(model = LLaMARunner(model = LLaMARunner(



  File "/home/wiss/zhang/code/open-eqa/openeqa/utils/llama_utils.py", line 29, in __init__
  File "/home/wiss/zhang/code/open-eqa/openeqa/utils/llama_utils.py", line 29, in __init__
  File "/home/wiss/zhang/code/open-eqa/openeqa/utils/llama_utils.py", line 29, in __init__
  File "/home/wiss/zhang/code/open-eqa/openeqa/utils/llama_utils.py", line 29, in __init__
        self.model = AutoModelForCausalLM.from_pretrained(self.model = AutoModelForCausalLM.from_pretrained(
        
self.model = AutoModelForCausalLM.from_pretrained(  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
self.model = AutoModelForCausalLM.from_pretrained(
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained

  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
                return model_class.from_pretrained(return model_class.from_pretrained(return model_class.from_pretrained(return model_class.from_pretrained(



  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3531, in from_pretrained
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3531, in from_pretrained
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3531, in from_pretrained
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3531, in from_pretrained
            ) = cls._load_pretrained_model() = cls._load_pretrained_model() = cls._load_pretrained_model(


      File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3958, in _load_pretrained_model
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3958, in _load_pretrained_model
) = cls._load_pretrained_model(  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3958, in _load_pretrained_model

  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3958, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
      File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 812, in _load_state_dict_into_meta_model
new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(    
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 812, in _load_state_dict_into_meta_model


  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 812, in _load_state_dict_into_meta_model
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/transformers/modeling_utils.py", line 812, in _load_state_dict_into_meta_model
        set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)    
set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/accelerate/utils/modeling.py", line 399, in set_module_tensor_to_device

  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/accelerate/utils/modeling.py", line 399, in set_module_tensor_to_device
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/accelerate/utils/modeling.py", line 399, in set_module_tensor_to_device
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/accelerate/utils/modeling.py", line 399, in set_module_tensor_to_device
            new_value = value.to(device)new_value = value.to(device)new_value = value.to(device)


    new_value = value.to(device)
torch.cudatorch.cuda.torch.cuda.OutOfMemoryError.OutOfMemoryError: torch.cudaOutOfMemoryError: CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 685.94 MiB is free. Including non-PyTorch memory, this process has 11.71 GiB memory in use. Process 2208058 has 11.71 GiB memory in use. Process 2208060 has 11.71 GiB memory in use. Process 2208057 has 11.71 GiB memory in use. Of the allocated memory 11.41 GiB is allocated by PyTorch, and 1.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables).: CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 685.94 MiB is free. Process 2208059 has 11.71 GiB memory in use. Including non-PyTorch memory, this process has 11.71 GiB memory in use. Process 2208060 has 11.71 GiB memory in use. Process 2208057 has 11.71 GiB memory in use. Of the allocated memory 11.41 GiB is allocated by PyTorch, and 1.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
OutOfMemoryErrorCUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 685.94 MiB is free. Process 2208059 has 11.71 GiB memory in use. Process 2208058 has 11.71 GiB memory in use. Including non-PyTorch memory, this process has 11.71 GiB memory in use. Process 2208057 has 11.71 GiB memory in use. Of the allocated memory 11.41 GiB is allocated by PyTorch, and 1.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
: 
CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 685.94 MiB is free. Process 2208059 has 11.71 GiB memory in use. Process 2208058 has 11.71 GiB memory in use. Process 2208060 has 11.71 GiB memory in use. Including non-PyTorch memory, this process has 11.71 GiB memory in use. Of the allocated memory 11.41 GiB is allocated by PyTorch, and 1.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
0, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 47990 MiB, 685 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
2, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
3, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 1230 MiB, 47445 MiB
0, NVIDIA RTX A6000, 19 %, 1 %, 49140 MiB, 35993 MiB, 12682 MiB
1, NVIDIA RTX A6000, 0 %, 0 %, 49140 MiB, 923 MiB, 47752 MiB
2, NVIDIA RTX A6000, 1 %, 0 %, 49140 MiB, 923 MiB, 47752 MiB
3, NVIDIA RTX A6000, 1 %, 0 %, 49140 MiB, 923 MiB, 47752 MiB
%Cpu(s):  0.1 us,  0.2 sy,  0.0 ni, 99.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem : 515796.2 total, 382069.0 free,   7795.7 used, 129318.7 buff/cache     
MiB Swap:   8192.0 total,   8192.0 free,      0.0 used. 508000.5 avail Mem 
[2025-01-20 17:27:14,300] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2208057) of binary: /home/wiss/zhang/anaconda3/envs/openeqa/bin/python
Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/wiss/zhang/anaconda3/envs/openeqa/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/wiss/zhang/code/open-eqa/openeqa/baselines/llama.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-01-20_17:27:14
  host      : worker-5
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 2208058)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-01-20_17:27:14
  host      : worker-5
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 2208059)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-01-20_17:27:14
  host      : worker-5
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 2208060)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-20_17:27:14
  host      : worker-5
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2208057)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
